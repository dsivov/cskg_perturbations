{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-17T10:24:26.242295Z",
          "iopub.status.busy": "2022-07-17T10:24:26.241950Z",
          "iopub.status.idle": "2022-07-17T10:24:58.681360Z",
          "shell.execute_reply": "2022-07-17T10:24:58.680323Z",
          "shell.execute_reply.started": "2022-07-17T10:24:26.242270Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBr9qClKt4pQ",
        "outputId": "4e574a27-480e-431f-996e-66c6e9c86b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 85.5 MB 106 kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 61.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.12.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 28.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=2533144527a9e3acd63a5c1a5dc732fb6a5c13150875c01cd98a1b7bd7b3c372\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sentence-transformers-2.2.2 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1\n",
            "--2022-07-17 10:37:11--  https://github.com/NEBULA3PR0JECT/cskg_data/raw/main/data.tgz\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/NEBULA3PR0JECT/cskg_data/main/data.tgz [following]\n",
            "--2022-07-17 10:37:11--  https://media.githubusercontent.com/media/NEBULA3PR0JECT/cskg_data/main/data.tgz\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 802627714 (765M) [application/octet-stream]\n",
            "Saving to: ‘data.tgz’\n",
            "\n",
            "data.tgz            100%[===================>] 765.45M   246MB/s    in 3.1s    \n",
            "\n",
            "2022-07-17 10:37:38 (246 MB/s) - ‘data.tgz’ saved [802627714/802627714]\n",
            "\n",
            "data/\n",
            "data/cskg_sentences1.tsv\n",
            "data/relations.pic\n",
            "data/vector.index\n",
            "data/vocab.pic\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install sentence_transformers\n",
        "!wget http://74.82.28.99:9000/cskg/data.tgz\n",
        "!tar -zxvf data.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XzLrp6_uzWO",
        "outputId": "cac72fd3-4881-4afa-9728-daad4a457f06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cskg_sentences1.tsv  relations.pic  vector.index  vocab.pic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to re-index embeddings. run build_index_db()"
      ],
      "metadata": {
        "id": "QCd0aV5KAf1S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-17T10:15:42.228926Z",
          "iopub.status.busy": "2022-07-17T10:15:42.228079Z",
          "iopub.status.idle": "2022-07-17T10:15:44.709894Z",
          "shell.execute_reply": "2022-07-17T10:15:44.708902Z",
          "shell.execute_reply.started": "2022-07-17T10:15:42.228896Z"
        },
        "id": "CbW2TLDWt4pT"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "import pickle\n",
        "import re\n",
        "from secrets import randbelow\n",
        "from typing import Callable, List, Tuple\n",
        "import csv\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, words) -> None:\n",
        "        self.idx_to_word = words\n",
        "        self.word_to_idx = {word: idx for idx, word in enumerate(words)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-17T10:18:57.701959Z",
          "iopub.status.busy": "2022-07-17T10:18:57.701360Z",
          "iopub.status.idle": "2022-07-17T10:18:57.743881Z",
          "shell.execute_reply": "2022-07-17T10:18:57.742948Z",
          "shell.execute_reply.started": "2022-07-17T10:18:57.701909Z"
        },
        "id": "6GgUpDRYt4pU"
      },
      "outputs": [],
      "source": [
        "class CSKG_EMBEDDINGS():\n",
        "    \n",
        "    def __init__(self) -> None:\n",
        "        print(\"init\")\n",
        "        #self.embedding_file = 'cskg_embeddings.csv'\n",
        "        self.model = SentenceTransformer('all-mpnet-base-v2')\n",
        "    \n",
        "    def read_embedding_file(self, file) -> Tuple[Vocab, np.ndarray]:\n",
        "        with open(file, 'r') as f:\n",
        "            vector_dim = len(next(f).split(\",\\\"\")[1].split(','))\n",
        "            file_len = len(f.readlines())\n",
        "            shape = tuple([file_len + 1,vector_dim])\n",
        "            print(shape)\n",
        "            embeddings = np.zeros(shape, dtype=np.float32)\n",
        "        with open(self.embedding_file, 'r') as d:\n",
        "            words = []\n",
        "            for i, line in tqdm(enumerate(d), total=shape[0]):\n",
        "                embedding = line.split(\"text_embedding,\")[1].split(\"\\\"\")[1].split(',')\n",
        "                word = line.split(\"text_embedding,\")[0].split(\",\")[0]\n",
        "                embedding = np.array([float(x) for x in embedding])\n",
        "                words.append(word)\n",
        "                embeddings[i] = embedding\n",
        "        self.words = words\n",
        "        vocab = Vocab(words)\n",
        "        \n",
        "        return (vocab, embeddings)\n",
        "\n",
        "\n",
        "    def build_index_db(self, metric: str, embeddings: np.ndarray, vocab):\n",
        "\n",
        "        if metric == 'cosine':\n",
        "            index = faiss.IndexFlatIP(embeddings.shape[-1])\n",
        "        elif metric == 'l2':\n",
        "            index = faiss.IndexFlatL2(embeddings.shape[-1])\n",
        "        else:\n",
        "            raise ValueError(f'Bad metric: {metric}')\n",
        "        index.add(embeddings)\n",
        "        faiss.write_index(index,\"data/vector.index\")  # save the index to disk\n",
        "        self.vocab = vocab\n",
        "        self.index = index\n",
        "\n",
        "        with open(\"data/vocab.pic\", 'wb') as f:\n",
        "                pickle.dump(vocab, f, protocol=4)\n",
        "        csv.field_size_limit(512000)\n",
        "        rel = []\n",
        "        with open(\"data/cskg_sentences1.tsv\") as file:\n",
        "            tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
        "            for line in tsv_file:\n",
        "                rel.append(line[3])\n",
        "        with open(\"data/relations.pic\", 'wb') as f:\n",
        "            pickle.dump(rel, f, protocol=4)\n",
        "    \n",
        "    def load_index_db(self):\n",
        "        with open(\"data/vocab.pic\", 'rb') as f:\n",
        "            self.vocab = pickle.load(f)\n",
        "        with open(\"data/relations.pic\", 'rb') as f:\n",
        "            self.relations = pickle.load(f)\n",
        "        self.index = faiss.read_index(\"data/vector.index\")\n",
        "        # print(\"VOCAB LOADED, size: \", len(self.vocab.))\n",
        "        # print(\"RELATIONS LOADED, size: \", len(self.relations))\n",
        "        print(\"INDEX Loaded\")\n",
        "    \n",
        "    def parse_relations(self, rel):\n",
        "        isa_relations = []\n",
        "        description_relations = []\n",
        "        property_values_relations = []\n",
        "        for  relations in rel.split('+'):\n",
        "            if 'isa' in relations:\n",
        "                isa_relations = relations.split('->')[0].split('isa(')\n",
        "            if 'description(' in relations:\n",
        "                description_relations = relations.split('->')[0].split('description(')\n",
        "            if 'property_values(' in relations:\n",
        "                property_values_relations = relations.split('->')[0].split('property_values(')\n",
        "            #print(relations)\n",
        "            if (len(isa_relations) > 0):\n",
        "                for isa in isa_relations[1].split(','):\n",
        "                    print(\"----------->ISA \",isa)\n",
        "            if (len(description_relations) > 0):\n",
        "                for desc in description_relations[1].split(','):\n",
        "                    print(\"------------>DR \",desc)\n",
        "            if (len(property_values_relations) > 0):\n",
        "                for pv in property_values_relations[1].split(','):\n",
        "                    print(\"----------->PVR \",pv)\n",
        "        #input()\n",
        "    \n",
        "    def query_for_events(self, query, topk):\n",
        "        query = \"at: and \" + query.replace(\" \", \"_\")\n",
        "        print(query)\n",
        "        query=np.array([self.model.encode(query)])\n",
        "        #faiss.normalize_L2(query)\n",
        "        scores, candidate_ids = self.index.search(query, topk)\n",
        "        scores = scores.flatten()\n",
        "        candidate_ids = candidate_ids.flatten()\n",
        "        top_k_indices = np.argsort(scores)[:topk]\n",
        "        scores = scores[top_k_indices]\n",
        "        candidate_ids = candidate_ids[top_k_indices]\n",
        "        \n",
        "        for candidate_id, score in zip(np.nditer(candidate_ids), np.nditer(scores)):\n",
        "            candidate = self.vocab.idx_to_word[candidate_id]\n",
        "            relation = self.relations[candidate_id]\n",
        "            # print(candidate, relation)\n",
        "            # print(candidate[0:5])\n",
        "            # if qtype == 'at' and candidate[0:3] == 'at:':\n",
        "            #     print(\"Candidate: \",candidate, score)\n",
        "            #     relation = relation.replace('\\\\\\'','')\n",
        "            #     cskg_emb.parse_relations(relation)\n",
        "            #if qtype == 'cn' and candidate[0:5] == '/c/en':\n",
        "            print(\"Candidate: \",candidate, score)\n",
        "            relation = relation.replace('\\\\\\'','')\n",
        "            self.parse_relations(relation)\n",
        "\n",
        "    def query_for_concepts(self, query, topk):\n",
        "        query = \"/c/en/ and \" + query.replace(\" \", \"_\")\n",
        "        print(query)\n",
        "        query=np.array([self.model.encode(query)])\n",
        "        #faiss.normalize_L2(query)\n",
        "        scores, candidate_ids = self.index.search(query, topk)\n",
        "        scores = scores.flatten()\n",
        "        candidate_ids = candidate_ids.flatten()\n",
        "        top_k_indices = np.argsort(scores)[:topk]\n",
        "        scores = scores[top_k_indices]\n",
        "        candidate_ids = candidate_ids[top_k_indices]\n",
        "        \n",
        "        for candidate_id, score in zip(np.nditer(candidate_ids), np.nditer(scores)):\n",
        "            candidate = self.vocab.idx_to_word[candidate_id]\n",
        "            relation = self.relations[candidate_id]\n",
        "            # print(candidate, relation)\n",
        "            # print(candidate[0:5])\n",
        "            # if qtype == 'at' and candidate[0:3] == 'at:':\n",
        "            #     print(\"Candidate: \",candidate, score)\n",
        "            #     relation = relation.replace('\\\\\\'','')\n",
        "            #     cskg_emb.parse_relations(relation)\n",
        "            #if qtype == 'cn' and candidate[0:5] == '/c/en':\n",
        "            print(\"Candidate: \",candidate, score)\n",
        "            relation = relation.replace('\\\\\\'','')\n",
        "            self.parse_relations(relation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-17T10:21:48.639553Z",
          "iopub.status.busy": "2022-07-17T10:21:48.638997Z",
          "iopub.status.idle": "2022-07-17T10:21:51.591009Z",
          "shell.execute_reply": "2022-07-17T10:21:51.589187Z",
          "shell.execute_reply.started": "2022-07-17T10:21:48.639510Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x3xapart4pX",
        "outputId": "5a9c1e32-06e8-49bf-e7c6-dd4920e71d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init\n",
            "INDEX Loaded\n"
          ]
        }
      ],
      "source": [
        "cskg_emb = CSKG_EMBEDDINGS()\n",
        "cskg_emb.load_index_db()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run \"Events\" Query"
      ],
      "metadata": {
        "id": "Yl7TYk2A9ngR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-17T10:23:30.534249Z",
          "iopub.status.busy": "2022-07-17T10:23:30.533906Z",
          "iopub.status.idle": "2022-07-17T10:23:30.799728Z",
          "shell.execute_reply": "2022-07-17T10:23:30.798824Z",
          "shell.execute_reply.started": "2022-07-17T10:23:30.534225Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y_dTI1xt4pX",
        "outputId": "916209cd-bb34-4382-dc7a-06fd8e4f02d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "at: and boat_in_the_sea\n",
            "Candidate:  /c/en/pair_of_oars 0.805495\n",
            "----------->PVR  /r/AtLocation /c/en/boat\n",
            "----------->PVR  /r/AtLocation /c/en/rowboat\n",
            "Candidate:  at:personx_takes_personx's_boat 0.8069\n",
            "----------->PVR  at:xAttr /c/en/adventurous\n",
            "----------->PVR  at:xAttr /c/en/boater\n",
            "----------->PVR  at:xAttr /c/en/brave\n",
            "----------->PVR  at:xAttr /c/en/marine\n",
            "----------->PVR  at:xAttr /c/en/sailor\n",
            "----------->PVR  at:xEffect at:gets_exercise_if_the_boat_has_no_motor_installed\n",
            "----------->PVR  at:xEffect at:gets_wet\n",
            "----------->PVR  at:xIntent /c/en/go_boating\n",
            "----------->PVR  at:xIntent at:to_go_fishing\n",
            "----------->PVR  at:xNeed at:find_the_boat\n",
            "----------->PVR  at:xNeed at:make_sure_the_boat_runs\n",
            "----------->PVR  at:xNeed at:to_gas_the_boat_up\n",
            "----------->PVR  at:xNeed at:to_get_permission\n",
            "----------->PVR  at:xNeed at:to_get_the_key\n",
            "----------->PVR  at:xNeed at:went_to_the_boating_place\n",
            "----------->PVR  at:xReact /c/en/relaxed\n",
            "----------->PVR  at:xReact /c/en/satisfied\n",
            "----------->PVR  at:xWant at:to_cruise_around_in_the_water\n",
            "----------->PVR  at:xWant at:to_go_fishing\n",
            "----------->PVR  at:xWant at:to_go_somewhere_with_boat\n",
            "----------->PVR  at:xWant at:to_return_the_keys\n",
            "----------->PVR  at:xWant at:to_sails_on_the_river_with_boat\n",
            "----------->PVR  at:xWant at:to_say_thank_you\n",
            "Candidate:  /c/en/life_preserver 0.8123781\n",
            "----------->PVR  /r/AtLocation /c/en/lifeboat\n",
            "----------->PVR  /r/AtLocation /c/en/swimming_pool\n",
            "Candidate:  at:personx_takes_the_boat 0.8133999\n",
            "----------->PVR  at:xAttr /c/en/confident\n",
            "----------->PVR  at:xAttr /c/en/mean\n",
            "----------->PVR  at:xAttr /c/en/rude\n",
            "----------->PVR  at:xAttr /c/en/seasick\n",
            "----------->PVR  at:xEffect at:becomes_wind_blown\n",
            "----------->PVR  at:xEffect at:comes_back_home_late_at_night\n",
            "----------->PVR  at:xEffect at:gets_drenched\n",
            "----------->PVR  at:xEffect at:reaches_his_destination_after_an_hour\n",
            "----------->PVR  at:xIntent at:to_go_fishing\n",
            "----------->PVR  at:xIntent at:to_go_out_on_the_water\n",
            "----------->PVR  at:xIntent at:to_travel_on_the_water\n",
            "----------->PVR  at:xNeed at:to_buy_the_boat_ticket\n",
            "----------->PVR  at:xNeed at:to_climb_into_it\n",
            "----------->PVR  at:xNeed at:to_go_near_the_boat\n",
            "----------->PVR  at:xNeed at:to_plan_a_trip\n",
            "----------->PVR  at:xReact /c/en/adventurous\n",
            "----------->PVR  at:xReact /c/en/content\n",
            "----------->PVR  at:xReact /c/en/happy\n",
            "----------->PVR  at:xWant at:to_cruise_to_hawaii\n",
            "----------->PVR  at:xWant at:to_go_fishing\n",
            "----------->PVR  at:xWant at:to_go_inside_the_sea\n",
            "----------->PVR  at:xWant at:to_see_the_fjords_of_norway\n",
            "Candidate:  /c/en/voyager 0.8388668\n",
            "----------->PVR  /r/AtLocation /c/en/bottom_of_sea\n",
            "----------->PVR  /r/CapableOf /c/en/board_ship\n",
            "Candidate:  at:personx_drops_anchor 0.83999705\n",
            "----------->PVR  at:xAttr /c/en/active\n",
            "----------->PVR  at:xAttr /c/en/clumsy\n",
            "----------->PVR  at:xAttr /c/en/dominant\n",
            "----------->PVR  at:xAttr /c/en/noisy\n",
            "----------->PVR  at:xAttr /c/en/responsible\n",
            "----------->PVR  at:xAttr /c/en/willful\n",
            "----------->PVR  at:xEffect at:person_x_brings_anchor_back_up\n",
            "----------->PVR  at:xEffect at:person_x_rests\n",
            "----------->PVR  at:xEffect at:they_jump_onto_the_jetty_and_tie_the_boat_up\n",
            "----------->PVR  at:xEffect at:they_steady_the_boat_to_get_off\n",
            "----------->PVR  at:xEffect at:they_turn_the_boat_engine_off\n",
            "----------->PVR  at:xEffect at:to_board_land\n",
            "----------->PVR  at:xEffect at:to_secure_boat\n",
            "----------->PVR  at:xIntent at:to_slow_a_boat\n",
            "----------->PVR  at:xNeed at:go_signal_from_superior\n",
            "----------->PVR  at:xNeed at:to_be_on_a_boat\n",
            "----------->PVR  at:xNeed at:to_be_on_a_watercraft\n",
            "----------->PVR  at:xNeed at:to_make_sure_it_is_safe\n",
            "----------->PVR  at:xReact /c/en/helpful\n",
            "----------->PVR  at:xWant at:check_anchor_is_working\n",
            "----------->PVR  at:xWant at:report_to_his_superior\n",
            "----------->PVR  at:xWant at:to_fish\n",
            "----------->PVR  at:xWant at:to_relax\n",
            "Candidate:  at:personx_goes_sailing 0.84799916\n",
            "----------->PVR  at:xAttr /c/en/active\n",
            "----------->PVR  at:xAttr /c/en/adventurous\n",
            "----------->PVR  at:xAttr /c/en/free_spirited\n",
            "----------->PVR  at:xAttr /c/en/happy\n",
            "----------->PVR  at:xAttr /c/en/relaxed\n",
            "----------->PVR  at:xAttr /c/en/skilled\n",
            "----------->PVR  at:xEffect /c/en/nothing\n",
            "----------->PVR  at:xEffect /c/en/sweaty\n",
            "----------->PVR  at:xEffect at:get_sea_legs_from_being_on_the_ocean_and_walks_funny_for_a_little_while_after_disembarking_vessel_onto_the_dock\n",
            "----------->PVR  at:xEffect at:get_windburn_from_being_out_on_the_salty_sea\n",
            "----------->PVR  at:xEffect at:gets_ff_boat\n",
            "----------->PVR  at:xEffect at:see__places\n",
            "----------->PVR  at:xIntent at:to_have_fun\n",
            "----------->PVR  at:xNeed at:set_the_sails\n",
            "----------->PVR  at:xNeed at:to_get_a_boat\n",
            "----------->PVR  at:xNeed at:to_go_to_the_water\n",
            "----------->PVR  at:xNeed at:to_put_the_sails_up\n",
            "----------->PVR  at:xNeed at:to_undock_the_boat\n",
            "----------->PVR  at:xReact /c/en/happy\n",
            "----------->PVR  at:xReact /c/en/invigorated\n",
            "----------->PVR  at:xReact /c/en/refreshed\n",
            "----------->PVR  at:xWant /c/en/relax\n",
            "----------->PVR  at:xWant at:explore_the_place_he_sailed_to\n",
            "----------->PVR  at:xWant at:tie_up_the_boat\n",
            "----------->PVR  at:xWant at:to_catch_fishes\n",
            "----------->PVR  at:xWant at:to_catch_some_fish\n",
            "----------->PVR  at:xWant at:to_explore_ocean\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(cskg_emb.query_for_events('boat_in_the_sea', 7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-17T10:22:21.073758Z",
          "iopub.status.busy": "2022-07-17T10:22:21.073198Z",
          "iopub.status.idle": "2022-07-17T10:22:21.447338Z",
          "shell.execute_reply": "2022-07-17T10:22:21.445853Z",
          "shell.execute_reply.started": "2022-07-17T10:22:21.073715Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsHX5bh-t4pY",
        "outputId": "b93eab45-5f80-4b40-a5e9-9e7edd69683e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/c/en/ and boat\n",
            "Candidate:  /c/en/speedboat/n 0.57942283\n",
            "----------->ISA  /c/en/boat/n\n",
            "----------->ISA  /c/en/motorboat/n\n",
            "Candidate:  /c/en/tugboat/n 0.57942283\n",
            "----------->ISA  /c/en/boat/n\n",
            "----------->ISA  /c/en/motorboat/n\n",
            "Candidate:  /c/en/runabout/n 0.57942283\n",
            "----------->ISA  /c/en/boat/n\n",
            "----------->ISA  /c/en/motorboat/n\n",
            "Candidate:  /c/en/sail/v/wn/navigation 0.61258924\n",
            "----------->ISA  /c/en/boat/v/wn/navigation\n",
            "Candidate:  /c/en/kayak/v/wn/sport 0.61258924\n",
            "----------->ISA  /c/en/boat/v/wn/navigation\n",
            "Candidate:  /c/en/canoe/v/wn/sport 0.61258924\n",
            "----------->ISA  /c/en/boat/v/wn/navigation\n",
            "Candidate:  /c/en/yacht/v/wn/navigation 0.61258924\n",
            "----------->ISA  /c/en/boat/v/wn/navigation\n",
            "Candidate:  /c/en/row/v/wn/motion 0.61258924\n",
            "----------->ISA  /c/en/boat/v/wn/navigation\n",
            "Candidate:  /c/en/bateau_mouche/n 0.61505157\n",
            "----------->ISA  /c/en/boat/n\n",
            "----------->ISA  /c/en/water_transportation_vehicle/n\n",
            "Candidate:  /c/en/trawl/n 0.62506956\n",
            "----------->ISA  /c/en/commercial_fishing_boat/n\n",
            "----------->ISA  /c/en/ship/n\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(cskg_emb.query_for_concepts('boat', 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run \"concepts\" query "
      ],
      "metadata": {
        "id": "cwFRQqg69bPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cskg_emb.query_for_concepts('einstein', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOIhuoaZ75fI",
        "outputId": "a2497b6a-6d7c-4232-9adb-ee5175f671a0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/c/en/ and einstein\n",
            "Candidate:  /c/en/outerspace 0.82073635\n",
            "------------>DR  /c/en/outer_space)\n",
            "----------->ISA  /c/en/all_around_us\n",
            "----------->ISA  \\/c/en/what_outside_earths_atmosphere\\\"\n",
            "------------>DR  /c/en/outer_space)\n",
            "Candidate:  /c/en/stephen_hawking 0.8772895\n",
            "----------->ISA  /c/en/physicist\n",
            "----------->ISA  /c/en/scientist/n\n",
            "Candidate:  /c/en/michio_kaku 0.87728983\n",
            "----------->ISA  /c/en/physicist\n",
            "----------->ISA  /c/en/scientist/n\n",
            "Candidate:  /c/en/paul_dirac 0.88489527\n",
            "----------->ISA  /c/en/scientist/n\n",
            "----------->ISA  /c/en/theoretical_physicist\n",
            "Candidate:  /c/en/general_relativity/n/wn/cognition 0.8888966\n",
            "----------->ISA  /c/en/general_relativity/n/wn/cognition\n",
            "----------->ISA  /c/en/scientific_theory/n/wn/cognition\n",
            "Candidate:  /c/en/astronomer/n/wn/astronomy 0.8953277\n",
            "----------->ISA  /c/en/physicist/n/wn/physics\n",
            "Candidate:  /c/en/biophysicist/n/wn/person 0.8953277\n",
            "----------->ISA  /c/en/physicist/n/wn/physics\n",
            "Candidate:  /c/en/acoustician/n/wn/person 0.8953277\n",
            "----------->ISA  /c/en/physicist/n/wn/physics\n",
            "Candidate:  /c/en/nuclear_physicist/n/wn/person 0.8953279\n",
            "----------->ISA  /c/en/physicist/n/wn/physics\n",
            "Candidate:  /c/en/charles_hard_townes/n/wn/person 0.8953279\n",
            "----------->ISA  /c/en/physicist/n/wn/physics\n",
            "None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
      }
    },
    "colab": {
      "name": "cskg_perturbations.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}