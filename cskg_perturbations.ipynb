{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T10:24:26.242295Z",
     "iopub.status.busy": "2022-07-17T10:24:26.241950Z",
     "iopub.status.idle": "2022-07-17T10:24:58.681360Z",
     "shell.execute_reply": "2022-07-17T10:24:58.680323Z",
     "shell.execute_reply.started": "2022-07-17T10:24:26.242270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.9/dist-packages (1.7.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.12.0+cu116)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (4.20.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.13.0+cu116)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (0.1.96)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence_transformers) (1.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence_transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2022-07-17 10:24:33--  https://github.com/NEBULA3PR0JECT/cskg_data/raw/main/data.tgz\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://media.githubusercontent.com/media/NEBULA3PR0JECT/cskg_data/main/data.tgz [following]\n",
      "--2022-07-17 10:24:33--  https://media.githubusercontent.com/media/NEBULA3PR0JECT/cskg_data/main/data.tgz\n",
      "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 802627714 (765M) [application/octet-stream]\n",
      "Saving to: ‘data.tgz.1’\n",
      "\n",
      "data.tgz.1          100%[===================>] 765.45M   228MB/s    in 3.4s    \n",
      "\n",
      "2022-07-17 10:24:45 (228 MB/s) - ‘data.tgz.1’ saved [802627714/802627714]\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "data/\n",
      "data/cskg_sentences1.tsv\n",
      "data/relations.pic\n",
      "data/vector.index\n",
      "data/vocab.pic\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu\n",
    "!pip install sentence_transformers\n",
    "!wget https://github.com/NEBULA3PR0JECT/cskg_data/raw/main/data.tgz\n",
    "!tar -zxvf data.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T10:15:42.228926Z",
     "iopub.status.busy": "2022-07-17T10:15:42.228079Z",
     "iopub.status.idle": "2022-07-17T10:15:44.709894Z",
     "shell.execute_reply": "2022-07-17T10:15:44.708902Z",
     "shell.execute_reply.started": "2022-07-17T10:15:42.228896Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pickle\n",
    "import re\n",
    "from secrets import randbelow\n",
    "from typing import Callable, List, Tuple\n",
    "import csv\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, words) -> None:\n",
    "        self.idx_to_word = words\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T10:18:57.701959Z",
     "iopub.status.busy": "2022-07-17T10:18:57.701360Z",
     "iopub.status.idle": "2022-07-17T10:18:57.743881Z",
     "shell.execute_reply": "2022-07-17T10:18:57.742948Z",
     "shell.execute_reply.started": "2022-07-17T10:18:57.701909Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSKG_EMBEDDINGS():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        print(\"init\")\n",
    "        #self.embedding_file = 'cskg_embeddings.csv'\n",
    "        self.model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    def read_embedding_file(self, file) -> Tuple[Vocab, np.ndarray]:\n",
    "        with open(file, 'r') as f:\n",
    "            vector_dim = len(next(f).split(\",\\\"\")[1].split(','))\n",
    "            file_len = len(f.readlines())\n",
    "            shape = tuple([file_len + 1,vector_dim])\n",
    "            print(shape)\n",
    "            embeddings = np.zeros(shape, dtype=np.float32)\n",
    "        with open(self.embedding_file, 'r') as d:\n",
    "            words = []\n",
    "            for i, line in tqdm(enumerate(d), total=shape[0]):\n",
    "                embedding = line.split(\"text_embedding,\")[1].split(\"\\\"\")[1].split(',')\n",
    "                word = line.split(\"text_embedding,\")[0].split(\",\")[0]\n",
    "                embedding = np.array([float(x) for x in embedding])\n",
    "                words.append(word)\n",
    "                embeddings[i] = embedding\n",
    "        self.words = words\n",
    "        vocab = Vocab(words)\n",
    "        \n",
    "        return (vocab, embeddings)\n",
    "\n",
    "\n",
    "    def build_index_db(self, metric: str, embeddings: np.ndarray, vocab):\n",
    "\n",
    "        if metric == 'cosine':\n",
    "            index = faiss.IndexFlatIP(embeddings.shape[-1])\n",
    "        elif metric == 'l2':\n",
    "            index = faiss.IndexFlatL2(embeddings.shape[-1])\n",
    "        else:\n",
    "            raise ValueError(f'Bad metric: {metric}')\n",
    "        index.add(embeddings)\n",
    "        faiss.write_index(index,\"data/vector.index\")  # save the index to disk\n",
    "        self.vocab = vocab\n",
    "        self.index = index\n",
    "\n",
    "        with open(\"data/vocab.pic\", 'wb') as f:\n",
    "                pickle.dump(vocab, f, protocol=4)\n",
    "        csv.field_size_limit(512000)\n",
    "        rel = []\n",
    "        with open(\"data/cskg_sentences1.tsv\") as file:\n",
    "            tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "            for line in tsv_file:\n",
    "                rel.append(line[3])\n",
    "        with open(\"data/relations.pic\", 'wb') as f:\n",
    "            pickle.dump(rel, f, protocol=4)\n",
    "    \n",
    "    def load_index_db(self):\n",
    "        with open(\"data/vocab.pic\", 'rb') as f:\n",
    "            self.vocab = pickle.load(f)\n",
    "        with open(\"data/relations.pic\", 'rb') as f:\n",
    "            self.relations = pickle.load(f)\n",
    "        self.index = faiss.read_index(\"data/vector.index\")\n",
    "        # print(\"VOCAB LOADED, size: \", len(self.vocab.))\n",
    "        # print(\"RELATIONS LOADED, size: \", len(self.relations))\n",
    "        print(\"INDEX Loaded\")\n",
    "    \n",
    "    def parse_relations(self, rel):\n",
    "        isa_relations = []\n",
    "        description_relations = []\n",
    "        property_values_relations = []\n",
    "        for  relations in rel.split('+'):\n",
    "            if 'isa' in relations:\n",
    "                isa_relations = relations.split('->')[0].split('isa(')\n",
    "            if 'description(' in relations:\n",
    "                description_relations = relations.split('->')[0].split('description(')\n",
    "            if 'property_values(' in relations:\n",
    "                property_values_relations = relations.split('->')[0].split('property_values(')\n",
    "            #print(relations)\n",
    "            if (len(isa_relations) > 0):\n",
    "                for isa in isa_relations[1].split(','):\n",
    "                    print(\"----------->ISA \",isa)\n",
    "            if (len(description_relations) > 0):\n",
    "                for desc in description_relations[1].split(','):\n",
    "                    print(\"------------>DR \",desc)\n",
    "            if (len(property_values_relations) > 0):\n",
    "                for pv in property_values_relations[1].split(','):\n",
    "                    print(\"----------->PVR \",pv)\n",
    "        #input()\n",
    "    \n",
    "    def query_for_events(self, query):\n",
    "        query = \"at:\" + query.replace(\" \", \"_\")\n",
    "        print(query)\n",
    "        query=np.array([self.model.encode(query)])\n",
    "        #faiss.normalize_L2(query)\n",
    "        scores, candidate_ids = self.index.search(query, 5)\n",
    "        scores = scores.flatten()\n",
    "        candidate_ids = candidate_ids.flatten()\n",
    "        top_k_indices = np.argsort(scores)[:5]\n",
    "        scores = scores[top_k_indices]\n",
    "        candidate_ids = candidate_ids[top_k_indices]\n",
    "        \n",
    "        for candidate_id, score in zip(np.nditer(candidate_ids), np.nditer(scores)):\n",
    "            candidate = self.vocab.idx_to_word[candidate_id]\n",
    "            relation = self.relations[candidate_id]\n",
    "            # print(candidate, relation)\n",
    "            # print(candidate[0:5])\n",
    "            # if qtype == 'at' and candidate[0:3] == 'at:':\n",
    "            #     print(\"Candidate: \",candidate, score)\n",
    "            #     relation = relation.replace('\\\\\\'','')\n",
    "            #     cskg_emb.parse_relations(relation)\n",
    "            #if qtype == 'cn' and candidate[0:5] == '/c/en':\n",
    "            print(\"Candidate: \",candidate, score)\n",
    "            relation = relation.replace('\\\\\\'','')\n",
    "            self.parse_relations(relation)\n",
    "\n",
    "    def query_for_concepts(self, query):\n",
    "        query = \"/c/en/\" + query.replace(\" \", \"_\")\n",
    "        print(query)\n",
    "        query=np.array([self.model.encode(query)])\n",
    "        #faiss.normalize_L2(query)\n",
    "        scores, candidate_ids = self.index.search(query, 5)\n",
    "        scores = scores.flatten()\n",
    "        candidate_ids = candidate_ids.flatten()\n",
    "        top_k_indices = np.argsort(scores)[:5]\n",
    "        scores = scores[top_k_indices]\n",
    "        candidate_ids = candidate_ids[top_k_indices]\n",
    "        \n",
    "        for candidate_id, score in zip(np.nditer(candidate_ids), np.nditer(scores)):\n",
    "            candidate = self.vocab.idx_to_word[candidate_id]\n",
    "            relation = self.relations[candidate_id]\n",
    "            # print(candidate, relation)\n",
    "            # print(candidate[0:5])\n",
    "            # if qtype == 'at' and candidate[0:3] == 'at:':\n",
    "            #     print(\"Candidate: \",candidate, score)\n",
    "            #     relation = relation.replace('\\\\\\'','')\n",
    "            #     cskg_emb.parse_relations(relation)\n",
    "            #if qtype == 'cn' and candidate[0:5] == '/c/en':\n",
    "            print(\"Candidate: \",candidate, score)\n",
    "            relation = relation.replace('\\\\\\'','')\n",
    "            self.parse_relations(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T10:21:48.639553Z",
     "iopub.status.busy": "2022-07-17T10:21:48.638997Z",
     "iopub.status.idle": "2022-07-17T10:21:51.591009Z",
     "shell.execute_reply": "2022-07-17T10:21:51.589187Z",
     "shell.execute_reply.started": "2022-07-17T10:21:48.639510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "INDEX Loaded\n"
     ]
    }
   ],
   "source": [
    "cskg_emb = CSKG_EMBEDDINGS()\n",
    "cskg_emb.load_index_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T10:23:30.534249Z",
     "iopub.status.busy": "2022-07-17T10:23:30.533906Z",
     "iopub.status.idle": "2022-07-17T10:23:30.799728Z",
     "shell.execute_reply": "2022-07-17T10:23:30.798824Z",
     "shell.execute_reply.started": "2022-07-17T10:23:30.534225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at:at:boat_in_the_sea\n",
      "Candidate:  at:personx_takes_personx's_boat 0.63855773\n",
      "----------->PVR  at:xAttr /c/en/adventurous\n",
      "----------->PVR  at:xAttr /c/en/boater\n",
      "----------->PVR  at:xAttr /c/en/brave\n",
      "----------->PVR  at:xAttr /c/en/marine\n",
      "----------->PVR  at:xAttr /c/en/sailor\n",
      "----------->PVR  at:xEffect at:gets_exercise_if_the_boat_has_no_motor_installed\n",
      "----------->PVR  at:xEffect at:gets_wet\n",
      "----------->PVR  at:xIntent /c/en/go_boating\n",
      "----------->PVR  at:xIntent at:to_go_fishing\n",
      "----------->PVR  at:xNeed at:find_the_boat\n",
      "----------->PVR  at:xNeed at:make_sure_the_boat_runs\n",
      "----------->PVR  at:xNeed at:to_gas_the_boat_up\n",
      "----------->PVR  at:xNeed at:to_get_permission\n",
      "----------->PVR  at:xNeed at:to_get_the_key\n",
      "----------->PVR  at:xNeed at:went_to_the_boating_place\n",
      "----------->PVR  at:xReact /c/en/relaxed\n",
      "----------->PVR  at:xReact /c/en/satisfied\n",
      "----------->PVR  at:xWant at:to_cruise_around_in_the_water\n",
      "----------->PVR  at:xWant at:to_go_fishing\n",
      "----------->PVR  at:xWant at:to_go_somewhere_with_boat\n",
      "----------->PVR  at:xWant at:to_return_the_keys\n",
      "----------->PVR  at:xWant at:to_sails_on_the_river_with_boat\n",
      "----------->PVR  at:xWant at:to_say_thank_you\n",
      "Candidate:  at:personx_drops_anchor 0.64071\n",
      "----------->PVR  at:xAttr /c/en/active\n",
      "----------->PVR  at:xAttr /c/en/clumsy\n",
      "----------->PVR  at:xAttr /c/en/dominant\n",
      "----------->PVR  at:xAttr /c/en/noisy\n",
      "----------->PVR  at:xAttr /c/en/responsible\n",
      "----------->PVR  at:xAttr /c/en/willful\n",
      "----------->PVR  at:xEffect at:person_x_brings_anchor_back_up\n",
      "----------->PVR  at:xEffect at:person_x_rests\n",
      "----------->PVR  at:xEffect at:they_jump_onto_the_jetty_and_tie_the_boat_up\n",
      "----------->PVR  at:xEffect at:they_steady_the_boat_to_get_off\n",
      "----------->PVR  at:xEffect at:they_turn_the_boat_engine_off\n",
      "----------->PVR  at:xEffect at:to_board_land\n",
      "----------->PVR  at:xEffect at:to_secure_boat\n",
      "----------->PVR  at:xIntent at:to_slow_a_boat\n",
      "----------->PVR  at:xNeed at:go_signal_from_superior\n",
      "----------->PVR  at:xNeed at:to_be_on_a_boat\n",
      "----------->PVR  at:xNeed at:to_be_on_a_watercraft\n",
      "----------->PVR  at:xNeed at:to_make_sure_it_is_safe\n",
      "----------->PVR  at:xReact /c/en/helpful\n",
      "----------->PVR  at:xWant at:check_anchor_is_working\n",
      "----------->PVR  at:xWant at:report_to_his_superior\n",
      "----------->PVR  at:xWant at:to_fish\n",
      "----------->PVR  at:xWant at:to_relax\n",
      "Candidate:  at:personx_goes_sailing 0.6854291\n",
      "----------->PVR  at:xAttr /c/en/active\n",
      "----------->PVR  at:xAttr /c/en/adventurous\n",
      "----------->PVR  at:xAttr /c/en/free_spirited\n",
      "----------->PVR  at:xAttr /c/en/happy\n",
      "----------->PVR  at:xAttr /c/en/relaxed\n",
      "----------->PVR  at:xAttr /c/en/skilled\n",
      "----------->PVR  at:xEffect /c/en/nothing\n",
      "----------->PVR  at:xEffect /c/en/sweaty\n",
      "----------->PVR  at:xEffect at:get_sea_legs_from_being_on_the_ocean_and_walks_funny_for_a_little_while_after_disembarking_vessel_onto_the_dock\n",
      "----------->PVR  at:xEffect at:get_windburn_from_being_out_on_the_salty_sea\n",
      "----------->PVR  at:xEffect at:gets_ff_boat\n",
      "----------->PVR  at:xEffect at:see__places\n",
      "----------->PVR  at:xIntent at:to_have_fun\n",
      "----------->PVR  at:xNeed at:set_the_sails\n",
      "----------->PVR  at:xNeed at:to_get_a_boat\n",
      "----------->PVR  at:xNeed at:to_go_to_the_water\n",
      "----------->PVR  at:xNeed at:to_put_the_sails_up\n",
      "----------->PVR  at:xNeed at:to_undock_the_boat\n",
      "----------->PVR  at:xReact /c/en/happy\n",
      "----------->PVR  at:xReact /c/en/invigorated\n",
      "----------->PVR  at:xReact /c/en/refreshed\n",
      "----------->PVR  at:xWant /c/en/relax\n",
      "----------->PVR  at:xWant at:explore_the_place_he_sailed_to\n",
      "----------->PVR  at:xWant at:tie_up_the_boat\n",
      "----------->PVR  at:xWant at:to_catch_fishes\n",
      "----------->PVR  at:xWant at:to_catch_some_fish\n",
      "----------->PVR  at:xWant at:to_explore_ocean\n",
      "Candidate:  at:personx_takes_the_boat 0.6875994\n",
      "----------->PVR  at:xAttr /c/en/confident\n",
      "----------->PVR  at:xAttr /c/en/mean\n",
      "----------->PVR  at:xAttr /c/en/rude\n",
      "----------->PVR  at:xAttr /c/en/seasick\n",
      "----------->PVR  at:xEffect at:becomes_wind_blown\n",
      "----------->PVR  at:xEffect at:comes_back_home_late_at_night\n",
      "----------->PVR  at:xEffect at:gets_drenched\n",
      "----------->PVR  at:xEffect at:reaches_his_destination_after_an_hour\n",
      "----------->PVR  at:xIntent at:to_go_fishing\n",
      "----------->PVR  at:xIntent at:to_go_out_on_the_water\n",
      "----------->PVR  at:xIntent at:to_travel_on_the_water\n",
      "----------->PVR  at:xNeed at:to_buy_the_boat_ticket\n",
      "----------->PVR  at:xNeed at:to_climb_into_it\n",
      "----------->PVR  at:xNeed at:to_go_near_the_boat\n",
      "----------->PVR  at:xNeed at:to_plan_a_trip\n",
      "----------->PVR  at:xReact /c/en/adventurous\n",
      "----------->PVR  at:xReact /c/en/content\n",
      "----------->PVR  at:xReact /c/en/happy\n",
      "----------->PVR  at:xWant at:to_cruise_to_hawaii\n",
      "----------->PVR  at:xWant at:to_go_fishing\n",
      "----------->PVR  at:xWant at:to_go_inside_the_sea\n",
      "----------->PVR  at:xWant at:to_see_the_fjords_of_norway\n",
      "Candidate:  at:personx_owns_a_boat 0.6926079\n",
      "----------->PVR  at:xAttr /c/en/adventurous\n",
      "----------->PVR  at:xAttr /c/en/daring\n",
      "----------->PVR  at:xAttr /c/en/envied\n",
      "----------->PVR  at:xAttr /c/en/laid_back\n",
      "----------->PVR  at:xAttr /c/en/rich\n",
      "----------->PVR  at:xAttr /c/en/successful\n",
      "----------->PVR  at:xEffect at:drives_the_boat\n",
      "----------->PVR  at:xEffect at:maintains_the_boat\n",
      "----------->PVR  at:xEffect at:parks_the_boat_at_dock\n",
      "----------->PVR  at:xEffect at:put_gas_in_it\n",
      "----------->PVR  at:xEffect at:takes_it_on_the_water\n",
      "----------->PVR  at:xIntent at:to_enjoy_boating\n",
      "----------->PVR  at:xIntent at:to_spend_time_in_the_water\n",
      "----------->PVR  at:xNeed /c/en/money\n",
      "----------->PVR  at:xNeed at:to_buy_a_boat\n",
      "----------->PVR  at:xNeed at:to_go_to_the_boat_shop\n",
      "----------->PVR  at:xNeed at:to_have_purchased_one\n",
      "----------->PVR  at:xNeed at:to_learn_to_drive_a_boat\n",
      "----------->PVR  at:xNeed at:to_save_up_money\n",
      "----------->PVR  at:xReact /c/en/affluent\n",
      "----------->PVR  at:xReact /c/en/proud\n",
      "----------->PVR  at:xWant at:take_it_out\n",
      "----------->PVR  at:xWant at:to_clean_it\n",
      "----------->PVR  at:xWant at:to_go_boating\n",
      "----------->PVR  at:xWant at:to_go_sailing\n",
      "----------->PVR  at:xWant at:to_go_swimming\n",
      "----------->PVR  at:xWant at:to_go_to_the_lake\n",
      "----------->PVR  at:xWant at:to_go_yachting\n",
      "----------->PVR  at:xWant at:to_spend_time_at_the_beach\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cskg_emb.query_for_events('at:boat_in_the_sea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T10:22:21.073758Z",
     "iopub.status.busy": "2022-07-17T10:22:21.073198Z",
     "iopub.status.idle": "2022-07-17T10:22:21.447338Z",
     "shell.execute_reply": "2022-07-17T10:22:21.445853Z",
     "shell.execute_reply.started": "2022-07-17T10:22:21.073715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/en//c/en/boat\n",
      "Candidate:  /c/en/tugboat/n 0.60683084\n",
      "----------->ISA  /c/en/boat/n\n",
      "----------->ISA  /c/en/motorboat/n\n",
      "Candidate:  /c/en/speedboat/n 0.6068311\n",
      "----------->ISA  /c/en/boat/n\n",
      "----------->ISA  /c/en/motorboat/n\n",
      "Candidate:  /c/en/runabout/n 0.6068311\n",
      "----------->ISA  /c/en/boat/n\n",
      "----------->ISA  /c/en/motorboat/n\n",
      "Candidate:  /c/en/houseboat/n 0.61075974\n",
      "----------->ISA  /c/en/boat/n\n",
      "----------->ISA  /c/en/fuel_powered_device/n\n",
      "----------->ISA  /c/en/home/n\n",
      "Candidate:  /c/en/kayak/v/wn/sport 0.622153\n",
      "----------->ISA  /c/en/boat/v/wn/navigation\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cskg_emb.query_for_concepts('/c/en/boat'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
