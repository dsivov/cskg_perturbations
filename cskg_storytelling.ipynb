{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-17T10:24:26.242295Z",
     "iopub.status.busy": "2022-07-17T10:24:26.241950Z",
     "iopub.status.idle": "2022-07-17T10:24:58.681360Z",
     "shell.execute_reply": "2022-07-17T10:24:58.680323Z",
     "shell.execute_reply.started": "2022-07-17T10:24:26.242270Z"
    },
    "id": "sBr9qClKt4pQ",
    "outputId": "4e574a27-480e-431f-996e-66c6e9c86b74"
   },
   "outputs": [],
   "source": [
    "!pip install faiss-gpu\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment it for first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://74.82.28.99:9000/cskg/data.tgz\n",
    "#!tar -zxvf data.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XzLrp6_uzWO",
    "outputId": "cac72fd3-4881-4afa-9728-daad4a457f06"
   },
   "outputs": [],
   "source": [
    "\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCd0aV5KAf1S"
   },
   "source": [
    "If you want to re-index embeddings. run build_index_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbW2TLDWt4pT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pickle\n",
    "import re\n",
    "from secrets import randbelow\n",
    "from typing import Callable, List, Tuple\n",
    "import csv\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "class Vocab:\n",
    "    def __init__(self, words) -> None:\n",
    "        self.idx_to_word = words\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "6GgUpDRYt4pU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSKG_EMBEDDINGS():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        print(\"init\")\n",
    "        #self.embedding_file = 'cskg_embeddings.csv'\n",
    "        self.model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    def read_embedding_file(self, file) -> Tuple[Vocab, np.ndarray]:\n",
    "        with open(file, 'r') as f:\n",
    "            vector_dim = len(next(f).split(\",\\\"\")[1].split(','))\n",
    "            file_len = len(f.readlines())\n",
    "            shape = tuple([file_len + 1,vector_dim])\n",
    "            print(shape)\n",
    "            embeddings = np.zeros(shape, dtype=np.float32)\n",
    "        with open(self.embedding_file, 'r') as d:\n",
    "            words = []\n",
    "            for i, line in tqdm(enumerate(d), total=shape[0]):\n",
    "                embedding = line.split(\"text_embedding,\")[1].split(\"\\\"\")[1].split(',')\n",
    "                word = line.split(\"text_embedding,\")[0].split(\",\")[0]\n",
    "                embedding = np.array([float(x) for x in embedding])\n",
    "                words.append(word)\n",
    "                embeddings[i] = embedding\n",
    "        self.words = words\n",
    "        vocab = Vocab(words)\n",
    "        \n",
    "        return (vocab, embeddings)\n",
    "\n",
    "\n",
    "    def build_index_db(self, metric: str, embeddings: np.ndarray, vocab):\n",
    "\n",
    "        if metric == 'cosine':\n",
    "            index = faiss.IndexFlatIP(embeddings.shape[-1])\n",
    "        elif metric == 'l2':\n",
    "            index = faiss.IndexFlatL2(embeddings.shape[-1])\n",
    "        else:\n",
    "            raise ValueError(f'Bad metric: {metric}')\n",
    "        index.add(embeddings)\n",
    "        faiss.write_index(index,\"data/vector.index\")  # save the index to disk\n",
    "        self.vocab = vocab\n",
    "        self.index = index\n",
    "\n",
    "        with open(\"data/vocab.pic\", 'wb') as f:\n",
    "                pickle.dump(vocab, f, protocol=4)\n",
    "        csv.field_size_limit(512000)\n",
    "        rel = []\n",
    "        with open(\"data/cskg_sentences1.tsv\") as file:\n",
    "            tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "            for line in tsv_file:\n",
    "                rel.append(line[3])\n",
    "        with open(\"data/relations.pic\", 'wb') as f:\n",
    "            pickle.dump(rel, f, protocol=4)\n",
    "    \n",
    "    def load_index_db(self):\n",
    "        with open(\"data/vocab.pic\", 'rb') as f:\n",
    "            self.vocab = pickle.load(f)\n",
    "        with open(\"data/relations.pic\", 'rb') as f:\n",
    "            self.relations = pickle.load(f)\n",
    "        self.index = faiss.read_index(\"data/vector.index\")\n",
    "        # print(\"VOCAB LOADED, size: \", len(self.vocab.))\n",
    "        # print(\"RELATIONS LOADED, size: \", len(self.relations))\n",
    "        print(\"INDEX Loaded\")\n",
    "    \n",
    "    def parse_relations(self, rel):\n",
    "        isa_relations = []\n",
    "        description_relations = []\n",
    "        property_values_relations = []\n",
    "        all_relations = {}\n",
    "        for  relations in rel.split('+'):\n",
    "            if 'isa' in relations:\n",
    "                isa_relations = relations.split('->')[0].split('isa(')\n",
    "            if 'description(' in relations:\n",
    "                description_relations = relations.split('->')[0].split('description(')\n",
    "            if 'property_values(' in relations:\n",
    "                property_values_relations = relations.split('->')[0].split('property_values(')\n",
    "            #print(relations)\n",
    "            if (len(isa_relations) > 1):\n",
    "                for isa in isa_relations[1].split(','):\n",
    "                    #print(\"----------->ISA \",isa)\n",
    "                    if len(isa.split(' ')) >= 2:\n",
    "                        rel = isa.split(' ')[0]\n",
    "                        node = isa.split(' ')[1]\n",
    "                        old_node = []\n",
    "                        if rel in all_relations:\n",
    "                            old_node = all_relations[rel]\n",
    "                            \n",
    "                        old_node.append(node)\n",
    "                        all_relations[rel] = old_node\n",
    "            if (len(description_relations) > 1):\n",
    "                for desc in description_relations[1].split(','):\n",
    "                    #print(\"------------>DR \",desc)\n",
    "                    if len(desc.split(' ')) >= 2:\n",
    "                        rel = desc.split(' ')[0]\n",
    "                        node = desc.split(' ')[1]\n",
    "                        old_node = []\n",
    "                        if rel in all_relations:\n",
    "                            old_node = all_relations[rel]\n",
    "\n",
    "                        old_node.append(node)\n",
    "                        all_relations[rel] = old_node\n",
    "            if (len(property_values_relations) > 1):\n",
    "                \n",
    "                for pv in property_values_relations[1].split(','):\n",
    "                    #print(\"----------->PVR \",pv)\n",
    "                    if len(pv.split(' ')) >= 2:\n",
    "                        rel = pv.split(' ')[0]\n",
    "                        node = pv.split(' ')[1]\n",
    "                        old_node = []\n",
    "                        if rel in all_relations:\n",
    "                            old_node = all_relations[rel]\n",
    "                            \n",
    "                        old_node.append(node)\n",
    "                        all_relations[rel] = old_node\n",
    "        return(all_relations)\n",
    "        #input()\n",
    "    \n",
    "    def query_for_events(self, rel, query, topk):\n",
    "        if rel == '':\n",
    "            query = \"at:\" + query.replace(\" \", \"_\")    \n",
    "        else:\n",
    "            query = \"at:\" + rel + \" at:\" + query.replace(\" \", \"_\")\n",
    "        print(\"Query: \",query)\n",
    "        query=np.array([self.model.encode(query)])\n",
    "        #faiss.normalize_L2(query)\n",
    "        scores, candidate_ids = self.index.search(query, topk)\n",
    "        scores = scores.flatten()\n",
    "        candidate_ids = candidate_ids.flatten()\n",
    "        top_k_indices = np.argsort(scores)[:topk]\n",
    "        scores = scores[top_k_indices]\n",
    "        candidate_ids = candidate_ids[top_k_indices]\n",
    "        all_events = []\n",
    "        all_candidates = {}\n",
    "        for candidate_id, score in zip(np.nditer(candidate_ids), np.nditer(scores)):\n",
    "            candidate = self.vocab.idx_to_word[candidate_id]\n",
    "            relation = self.relations[candidate_id]\n",
    "            relation = relation.replace('\\\\\\'','')\n",
    "            kg_path = self.parse_relations(relation)\n",
    "            for kg_rel in kg_path:\n",
    "                for nbr in kg_path[kg_rel]:\n",
    "                    #print(kg_rel, '->', nbr)\n",
    "                    all_events.append({'neighbor': nbr, 'kg_relation': kg_rel, 'candidate': candidate, 'score': score})\n",
    "                    all_candidates[candidate] = {'candidate': candidate, 'score': score, 'kg_path': kg_path}\n",
    "        #print(all_events)\n",
    "        return(all_events, all_candidates)\n",
    "\n",
    "    def query_for_concepts(self, query, topk):\n",
    "        query = \"It is a /c/en/\" + query.replace(\" \", \" /c/en/\")\n",
    "        print(query)\n",
    "        query=np.array([self.model.encode(query)])\n",
    "        #faiss.normalize_L2(query)\n",
    "        scores, candidate_ids = self.index.search(query, topk)\n",
    "        scores = scores.flatten()\n",
    "        candidate_ids = candidate_ids.flatten()\n",
    "        top_k_indices = np.argsort(scores)[:topk]\n",
    "        scores = scores[top_k_indices]\n",
    "        candidate_ids = candidate_ids[top_k_indices]\n",
    "        \n",
    "        for candidate_id, score in zip(np.nditer(candidate_ids), np.nditer(scores)):\n",
    "            candidate = self.vocab.idx_to_word[candidate_id]\n",
    "            relation = self.relations[candidate_id]\n",
    "            relation = relation.replace('\\\\\\'','')\n",
    "            self.parse_relations(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9x3xapart4pX",
    "outputId": "5a9c1e32-06e8-49bf-e7c6-dd4920e71d6d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "INDEX Loaded\n"
     ]
    }
   ],
   "source": [
    "cskg_emb = CSKG_EMBEDDINGS()\n",
    "cskg_emb.load_index_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  at:xNeed at:man_breaks_the_car_window\n",
      "Query:  at:xNeed at:man_wearing_black_drerss\n",
      "Query:  at:xNeed at:suspicious_man_in_night_street\n"
     ]
    }
   ],
   "source": [
    "#query1 = 'men in tuxedo presents ring'\n",
    "#query2 = 'women wears white dress'\n",
    "\n",
    "\n",
    "query1 = 'suspicious man in night street'\n",
    "query2 = 'man breaks the car window'\n",
    "query3 = 'man wearing black drerss'\n",
    "all_rel_right, c1 = cskg_emb.query_for_events('xNeed', query2, 5)\n",
    "all_rel_middle, c2 = cskg_emb.query_for_events('xNeed', query3, 5)\n",
    "all_rel_left, c3 = cskg_emb.query_for_events('xNeed', query1, 5)\n",
    "#print(\"R->\", all_rel_right)\n",
    "#print(\"L-> \", all_rel_left)\n",
    "# rel_right = []\n",
    "# rel_left = []\n",
    "left_nodes = []\n",
    "right_nodes = []\n",
    "middle_nodes = []\n",
    "for n in all_rel_left:\n",
    "    left_nodes.append(n['neighbor'])\n",
    "for n in all_rel_right:\n",
    "    right_nodes.append(n['neighbor'])\n",
    "for n in all_rel_middle:\n",
    "    middle_nodes.append(n['neighbor'])\n",
    "#all_nodes = list(dict.fromkeys(all_nodes))\n",
    "embeddings_left = cskg_emb.model.encode(left_nodes, convert_to_tensor=True)\n",
    "embeddings_right = cskg_emb.model.encode(right_nodes, convert_to_tensor=True)\n",
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "# # cosine_scores = util.cos_sim(embeddings_left, embeddings_right)\n",
    "\n",
    "# # #Find the pairs with the highest cosine similarity scores\n",
    "# # pairs = []\n",
    "# # for i in range(len(cosine_scores)-1):\n",
    "# #     for j in range(i+1, len(cosine_scores)):\n",
    "# #         pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "# # #Sort scores in decreasing order\n",
    "# # pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# # for pair in pairs[0:50]:\n",
    "# #     i, j = pair['index']\n",
    "# #     print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(left_nodes[i], right_nodes[j], pair['score']))\n",
    "# for cand in all_rel_right.values():\n",
    "#     #print(\"Right: \",cand)\n",
    "#     for path in cand['kg_path'].values():\n",
    "#         #print(path)\n",
    "#         for val in path:\n",
    "#             rel_right.append(val)\n",
    "# for cand in all_rel_left.values():\n",
    "#     #print(\"Left: \",cand)\n",
    "#     for path in cand['kg_path'].values():\n",
    "#         #print(path)\n",
    "#         for val in path:\n",
    "#             rel_left.append(val)\n",
    "# print(\"Left-> \",rel_left)\n",
    "# print(\"Right-> \", rel_right)\n",
    "vectors_number = min(len(left_nodes), len(right_nodes))\n",
    "#embeddings1 = cskg_emb.model.encode(rel_right, convert_to_tensor=True)\n",
    "#embeddings2 = cskg_emb.model.encode(rel_left, convert_to_tensor=True)\n",
    "\n",
    "# cosine_scores = util.cos_sim(embeddings_left, embeddings_right)\n",
    "\n",
    "# all = []\n",
    "\n",
    "\n",
    "# for i in range(vectors_number):\n",
    "#     all.append(( cosine_scores[i][i].item(), left_nodes[i] + '->' + right_nodes[i], i))\n",
    "#     #print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(rel_right[i], rel_left[i], cosine_scores[i][i]))\n",
    "# all.sort(reverse=True)\n",
    "# for pair in all:\n",
    "#     print(\"pair:-> \", pair)\n",
    "#     print(\"candidate L:-> \", all_rel_left[pair[2]]['candidate'])\n",
    "#     print(\"candidate R:-> \", all_rel_right[pair[2]]['candidate'])\n",
    "#print(all[:30])\n",
    "sentences = left_nodes + right_nodes + middle_nodes\n",
    "sentences = list(dict.fromkeys(sentences))\n",
    "embeddings = cskg_emb.model.encode(sentences, convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "#Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  at:dark_street\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:dark_street\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:man_is_criminal\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:dark_street\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:car_in_park_lot\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_wearing_dark\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_has_black_sunglasses\n",
      "Query:  at:man_breaks_down_a_car_door\n",
      "Query:  at:man_is_criminal\n",
      "[[], [], [], [], [], [], [(0.6858571767807007, \"at:personx_left_personz's_____behind_persony->at:personx_tells_persony_the_name\", 2)], [(0.6697714924812317, \"at:personx_parallels_park->at:personx_raises_persony's_eyebrows\", 33)], [], [(0.7638311386108398, \"at:personx_moves_personx's_car->at:personx_takes_it_to_a_mechanic\", 3), (0.7350645065307617, '/c/en/concept_car->/c/en/take_car_for_drive', 18), (0.7110497951507568, \"at:personx_finds_parking->at:personx_gets_persony's_car_back\", 1)], [], [(0.6858571767807007, \"at:personx_tells_persony_the_name->at:personx_left_personz's_____behind_persony\", 2)], [(0.8191404342651367, 'at:personx_sees_the_man->at:personx_looks_around_persony', 23), (0.7328075170516968, 'at:personx_gets_back_to_persony->at:personx_casts_a_shadow', 22), (0.727535605430603, \"at:personx_talks_to_the_man->at:personx_wears_persony's_glasses\", 0), (0.6903632879257202, 'at:personx_brings_persony_forth->at:personx_wears_glasses', 20), (0.6813279986381531, \"at:personx_meets_a_man->at:personx_breaks_personx's_glasses\", 1)], [], [(0.7155451774597168, 'at:personx_sees_the_man->at:personx_takes_it_into_the_shop', 23)], [], [(0.6697714924812317, \"at:personx_raises_persony's_eyebrows->at:personx_parallels_park\", 33)], [(0.8191404342651367, 'at:personx_looks_around_persony->at:personx_sees_the_man', 23), (0.7328075170516968, 'at:personx_casts_a_shadow->at:personx_gets_back_to_persony', 22), (0.727535605430603, \"at:personx_wears_persony's_glasses->at:personx_talks_to_the_man\", 0), (0.6903632879257202, 'at:personx_wears_glasses->at:personx_brings_persony_forth', 20), (0.6813279986381531, \"at:personx_breaks_personx's_glasses->at:personx_meets_a_man\", 1)], [(0.6858688592910767, 'at:personx_calls_the_man->at:personx_takes_persony_prisoner', 30), (0.6722009778022766, 'at:personx_talks_to_the_man->at:personx_gets_arrested', 12)], [(0.7226399183273315, \"at:personx_takes_persony's_glasses->at:personx_pops_the_hood\", 6), (0.7184814214706421, 'at:personx_sees_the_man->at:personx_takes_it_to_a_mechanic', 3), (0.7132701873779297, 'at:personx_looks_around_persony->at:personx_takes_it_into_the_shop', 23)], [], [], [], [(0.6858688592910767, 'at:personx_takes_persony_prisoner->at:personx_calls_the_man', 30), (0.6722009778022766, 'at:personx_gets_arrested->at:personx_talks_to_the_man', 12)], [(0.6866316795349121, \"at:personx_has_done_something_wrong->at:personx_hits_persony's_car\", 35), (0.6772972345352173, \"at:personx_puts_personx's_____to_death->at:personx_crashes_the_car\", 25), (0.6735430955886841, \"at:personx_takes_persony_prisoner->at:personx_wrecks_persony's_car\", 30), (0.6713957786560059, 'at:personx_breaks_a_law->at:personx_steals_the_car', 17)], [], [(0.7638311386108398, \"at:personx_takes_it_to_a_mechanic->at:personx_moves_personx's_car\", 3), (0.7350645065307617, '/c/en/take_car_for_drive->/c/en/concept_car', 18), (0.7110497951507568, \"at:personx_gets_persony's_car_back->at:personx_finds_parking\", 1)], [(0.7155451774597168, 'at:personx_takes_it_into_the_shop->at:personx_sees_the_man', 23)], [(0.7226399183273315, \"at:personx_pops_the_hood->at:personx_takes_persony's_glasses\", 6), (0.7184814214706421, 'at:personx_takes_it_to_a_mechanic->at:personx_sees_the_man', 3), (0.7132701873779297, 'at:personx_takes_it_into_the_shop->at:personx_looks_around_persony', 23)], [(0.6866316795349121, \"at:personx_hits_persony's_car->at:personx_has_done_something_wrong\", 35), (0.6772972345352173, \"at:personx_crashes_the_car->at:personx_puts_personx's_____to_death\", 25), (0.6735430955886841, \"at:personx_wrecks_persony's_car->at:personx_takes_persony_prisoner\", 30), (0.6713957786560059, 'at:personx_steals_the_car->at:personx_breaks_a_law', 17)]]\n"
     ]
    }
   ],
   "source": [
    "#query1 = 'suspicious man in night street'\n",
    "#query2 = 'man breaks the car window'\n",
    "#query3 = 'man wearing black drerss'\n",
    "#triplets = ['man has baseball cap', 'green grass on field', 'tribune full of people', 'people play game']\n",
    "triplets = ['dark street', 'car in park lot', 'man wearing dark', 'man has black sunglasses', 'man is criminal', 'man breaks down a car door']\n",
    "all_cand = []\n",
    "for triple1 in triplets:\n",
    "    for triple2 in triplets:\n",
    "        if triple2 != triple1:\n",
    "            #print(triple1, \"->\", triple2)\n",
    "            a, event1 = cskg_emb.query_for_events('', triple1, 40)\n",
    "            b, event2 = cskg_emb.query_for_events('', triple2, 40)\n",
    "            #print(event1.keys(), \"->\", event2.keys())\n",
    "            embeddings1 = cskg_emb.model.encode(list(event1.keys()), convert_to_tensor=True)\n",
    "            embeddings2 = cskg_emb.model.encode(list(event2.keys()), convert_to_tensor=True)\n",
    "            cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "            all = []\n",
    "\n",
    "            vectors_number = min(len(list(event1.keys())), len(list(event2.keys())))\n",
    "            for i in range(vectors_number):\n",
    "                if  cosine_scores[i][i].item() > 0.65:\n",
    "                    all.append(( cosine_scores[i][i].item(), list(event1.keys())[i] + '->' + list(event2.keys())[i], i))\n",
    "                #print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(rel_right[i], rel_left[i], cosine_scores[i][i]))\n",
    "            all.sort(reverse=True)\n",
    "            #for pair in all:\n",
    "                #print(\"pair:-> \", pair)\n",
    "                #print(\"candidate L:-> \", all_rel_left[pair[2]]['candidate'])\n",
    "                #print(\"candidate R:-> \", all_rel_right[pair[2]]['candidate'])\n",
    "            #print(all[:10])\n",
    "            all_cand.append(all)\n",
    "print(all_cand)          \n",
    "#     #for cand in c.keys():\n",
    "#     all_cand.append(c.keys())\n",
    "    \n",
    "# # all_rel_right, c1 = cskg_emb.query_for_events('xEffect', query2, 15)\n",
    "# # all_rel_middle, c2 = cskg_emb.query_for_events('xEffect', query3, 15)\n",
    "# # all_rel_left, c3 = cskg_emb.query_for_events('xEffect', query1, 15)\n",
    "# #all_cand = list(c1.keys()) +list(c2.keys()) + list(c3.keys())\n",
    "# sentences = list(dict.fromkeys(all_cand))\n",
    "# embeddings = cskg_emb.model.encode(sentences, convert_to_tensor=True)\n",
    "# cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "# #Find the pairs with the highest cosine similarity scores\n",
    "# pairs = []\n",
    "# for i in range(len(cosine_scores)-1):\n",
    "#     for j in range(i+1, len(cosine_scores)):\n",
    "#         pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "# #Sort scores in decreasing order\n",
    "# pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "# for pair in pairs:\n",
    "    # i, j = pair['index']\n",
    "    # print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at:personx_exchanges_insurance_information', \"at:personx_hits_personx's_car\", 'at:personx_assesses_the_damage', 'at:personx_pops_the_hood', 'at:personx_causes_an_accident', 'at:personx_reports_the_____to_the_police', 'at:personx_keeps_track_of_persony', 'at:personx_finds_the_culprit', \"at:personx_retraces_persony's_steps\", 'at:personx_asks_____what_happened', 'at:personx_immediately_went', 'at:personx_calls_the_man', 'at:personx_waits_until_the_next_day', 'at:personx_comes_within_the_scope', 'at:personx_helps_the_man']\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "for pair in pairs:\n",
    "    i, j = pair['index']\n",
    "    #print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))\n",
    "    all.append(sentences[i])\n",
    "    all.append(sentences[j])\n",
    "all =  list(dict.fromkeys(all))\n",
    "cands = []\n",
    "for i in all_rel_right:\n",
    "    if i['neighbor'] in all:\n",
    "        cands.append(i['candidate'])\n",
    "for i in all_rel_left:\n",
    "    if i['neighbor'] in all:\n",
    "        cands.append(i['candidate'])\n",
    "for i in all_rel_middle:\n",
    "    if i['neighbor'] in all:\n",
    "        cands.append(i['candidate'])\n",
    "cands = list(dict.fromkeys(cands))\n",
    "print(cands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl7TYk2A9ngR"
   },
   "source": [
    "Run \"Events\" Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y_dTI1xt4pX",
    "outputId": "916209cd-bb34-4382-dc7a-06fd8e4f02d9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def walk_by_timeline(direction, query):  \n",
    "    \n",
    "    if direction == 'forward':\n",
    "        category = 'xWant'\n",
    "    elif direction == 'backward':\n",
    "        category = 'xNeed'\n",
    "    else:\n",
    "        print(\"No such direction: \", direction)\n",
    "    #print(\"Next q: \",category, query)\n",
    "    all_rel = cskg_emb.query_for_events(category, query, 7)\n",
    "    #print(\"All: \", all_rel)\n",
    "    outputs = []\n",
    "    for alr in all_rel:\n",
    "        #print (alr)\n",
    "        for x in all_rel[alr]['kg_path']:\n",
    "            if x == 'at:'+category:\n",
    "                for xneed in all_rel[alr]['kg_path'][x]:\n",
    "                    outputs.append(xneed)\n",
    "    return(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwards = walk_by_timeline('forward','men in tuxedo')\n",
    "print(forwards)\n",
    "all_forwards = []\n",
    "all_forwards.append(forwards)\n",
    "for topk in range(3):\n",
    "    if (len(forwards) > 0):\n",
    "        for forward in forwards:\n",
    "            #print(\"Next: \",forward)\n",
    "            forwards = walk_by_timeline('forward', forward.replace('at:', '').replace('_',' '))\n",
    "            all_forwards.append(forwards)\n",
    "print(all_forwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards = walk_by_timeline('backward','women in white dress')\n",
    "#print(forwards)\n",
    "all_backwards = []\n",
    "all_backwards.append(backwards)\n",
    "for topk in range(3):\n",
    "    if (len(backwards) > 0):\n",
    "        for backward in backwards:\n",
    "            #print(\"Next: \",forward)\n",
    "            backwards = walk_by_timeline('backward', forward.replace('at:', '').replace('_',' '))\n",
    "            all_backwards.append(backwards)\n",
    "#print(all_forwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forwards = []\n",
    "for ff in all_forwards:\n",
    "    for f in ff:\n",
    "        forwards.append(f)\n",
    "print(len(forwards))\n",
    "backwards = []\n",
    "for ff in all_backwards:\n",
    "    for f in ff:\n",
    "        backwards.append(f)\n",
    "print(len(backwards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = cskg_emb.model.encode(backwards, convert_to_tensor=True)\n",
    "embeddings2 = cskg_emb.model.encode(forwards, convert_to_tensor=True)\n",
    "from sentence_transformers import util\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(backwards)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(backwards[i], forwards[i], cosine_scores[i][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsHX5bh-t4pY",
    "outputId": "b93eab45-5f80-4b40-a5e9-9e7edd69683e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cskg_emb.query_for_concepts('men car night street', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwFRQqg69bPf"
   },
   "source": [
    "Run \"concepts\" query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOIhuoaZ75fI",
    "outputId": "a2497b6a-6d7c-4232-9adb-ee5175f671a0"
   },
   "outputs": [],
   "source": [
    "print(cskg_emb.query_for_concepts('george_washington', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cskg_perturbations.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
